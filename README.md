# Predicting Scholarly Impact with Retrieval-Augmented LLMs

## Description:
This repository contains code for predicting the impact of research papers using Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG). We use FAISS-based dense retrieval, self-consistency prompting, and models like Llama 3, Mistral, and Gemma to enhance the prediction accuracy of Field Citation Ratios (FCR).

This approach provides an alternative to citation-based metrics by leveraging text-based analysis of papers, improving impact assessment before citations accumulate.

---

Create a virtual environment: (Step 1):

mkdir my_project

cd my_project

Activate the virtual environment (Step 2):

env\Scripts\activate (windows)

source env/bin/activate

install related libraries (Step 3):

pip install -r requirements.txt

Code Workflow & How to Run (Step 4):
ðŸ“‚ Dataset Preparation

    Download the file (research_papers.csv) from HuggingFace and save it in a folder called /dataset.
    The file has already been preprocessed with the following steps:
        Cleans text data
        Extracts title, abstract, and readability features
        Normalizes Field Citation Ratio (FCR) scores

ðŸ“‚ Running Prediction Models

    Zero-Shot Baseline Prediction:
    Run zero_shot.py to predict FCR using LLM-only prompting (without retrieval).

Retrieval-Augmented Prediction (RAG):
Run dense retrieval-based predictions using LLMs with FAISS:

    Gemma: python gemma.py
    Llama 3: python llama3.py
    Mistral: python mistral.py

Evaluating Model Performance:

    MAE, RMSE, and NDCG scores are automatically calculated after running the model.
    Results are saved in results/ as CSV files.




## Code and Datasets

```bash

scholarly-impact-rag/
â”‚
â”œâ”€â”€ dataset/                     # Datasets for training & evaluation
â”‚   â”œâ”€â”€ df_scholarly_impact.csv  # Main dataset (FCR-labeled research papers)
â”‚   â”œâ”€â”€ dataset_creation.ipynb  # Dataset preprocessing notebook

â”œâ”€â”€ src/                                # Core implementation scripts
â”‚   â”œâ”€â”€ zero_shot
â”‚         â”œâ”€â”€ zero_shot.py              # Zero-shot LLM prediction module 
â”‚         â”œâ”€â”€ zero_shot.ipynb           # Zero-shot prompting notebook
â”‚   â”œâ”€â”€ gemma
â”‚        â”œâ”€â”€ gemma.py                   # Gemma-7b rag module
â”‚        â”œâ”€â”€ gemma.ipynb                # Gemma-7b model notebook
â”‚   â”œâ”€â”€ llama3
â”‚        â”œâ”€â”€ llama3.py                  # Llama 3-8b rag module
â”‚        â”œâ”€â”€ llama3.ipynb               # Llama 3-8b model notebook
â”‚   â”œâ”€â”€ mistral
â”‚        â”œâ”€â”€ mistral.py                 # Mistral rag module
â”‚        â”œâ”€â”€ mistral.ipynb              # Mistral model notebook
â”‚
â”‚
â”œâ”€â”€ results/                   # Model performance results
â”‚   â”œâ”€â”€ gemma
â”‚        â”œâ”€â”€ gemma rag predictions.csv                 
â”‚        â”œâ”€â”€ gemma zero-shot predictions.csv
â”‚   â”œâ”€â”€ llama3
â”‚        â”œâ”€â”€ llama3 rag predictions.csv                 
â”‚        â”œâ”€â”€ llama3 zero-shot predictions.csv
â”‚   â”œâ”€â”€ mistral
â”‚        â”œâ”€â”€ mistral rag predictions.csv                 
â”‚        â”œâ”€â”€ mistral zero-shot predictions.csv
â”‚   â”œâ”€â”€ metrics
â”‚        â”œâ”€â”€ zero-shot metrics.csv                 
â”‚        â”œâ”€â”€ gemma rag metrics.csv
â”‚        â”œâ”€â”€ llama3 rag metrics.csv
â”‚        â”œâ”€â”€ mistral rag metrics.csv
â”‚ 
â”‚
â”œâ”€â”€ requirements.txt           # List of dependencies
â”œâ”€â”€ README.md                  # Project documentation

'''
