# Predicting Scholarly Impact with Retrieval-Augmented LLMs

## Description:
This repository contains code for predicting the **scholarly impact of research papers** using **Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG).** It utilizes **FAISS-based dense retrieval**, **self-consistency prompting**, and models like **Llama 3, Mistral, and Gemma** to enhance the prediction accuracy of **Field Citation Ratios (FCR).**

This approach provides an **alternative to citation-based metrics** by leveraging **text-based analysis** of papers, improving impact assessment **before citations accumulate.**

---


Create a virtual environment: (Step 1):
mkdir my_project

cd my_project
Activate the virtual environment (Step 2):

env\Scripts\activate (windows)

source env/bin/activate
install related libraries (Step 3):

pip install -r requirements.txt
code workflow (how to run)

Code Workflow & How to Run (Step 4):
ðŸ“‚ Dataset Preparation

    Load the dataset from data/ (e.g., df_scholarly_impact.csv).
    Preprocess the dataset using dataset_creation.ipynb, which:
        Cleans text data
        Extracts title, abstract, and readability features
        Normalizes Field Citation Ratio (FCR) scores

ðŸ“‚ Running Prediction Models

    Zero-Shot Baseline Prediction:
    Run zero_shot.py to predict FCR using LLM-only prompting (without retrieval).

Retrieval-Augmented Prediction (RAG):
Run dense retrieval-based predictions using LLMs with FAISS:

    Gemma: python gemma.py
    Llama 3: python llama3.py
    Mistral: python mistral.py

Evaluating Model Performance:

    MAE, RMSE, and NDCG scores are automatically calculated after running the model.
    Results are saved in results/ as CSV files.




## Code and Datasets

```bash

scholarly-impact-rag/
â”‚
â”œâ”€â”€ dataset/                     # Datasets for training & evaluation
â”‚   â”œâ”€â”€ df_scholarly_impact.csv  # Main dataset (FCR-labeled research papers)
â”‚   â”œâ”€â”€ dataset_creation.ipynb  # Dataset preprocessing notebook

â”œâ”€â”€ src/                      # Core implementation scripts
â”‚   â”œâ”€â”€ zero_shot.py           # Zero-shot LLM prediction module
â”‚   â”œâ”€â”€ gemma.py               # Gemma-7b rag module
â”‚   â”œâ”€â”€ llama3.py              # Llama 3-8b rag module
â”‚   â”œâ”€â”€ mistral.py             # Mistral rag module
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter Notebooks for Analysis
â”‚   â”œâ”€â”€ zero_shot.ipynb         # Zero-shot prompting notbook
â”‚   â”œâ”€â”€ gemma.ipynb             # Gemma-7b model notbook
â”‚   â”œâ”€â”€ llama3.ipynb            # Llama 3-8b model notbook
â”‚   â”œâ”€â”€ mistral.ipynb           # Mistral model notbook
â”‚
â”œâ”€â”€ results/                   # Model performance results
â”‚   â”œâ”€â”€ predictions_gemma.csv
â”‚   â”œâ”€â”€ predictions_llama3.csv
â”‚   â”œâ”€â”€ predictions_mistral.csv
â”‚
â”œâ”€â”€ requirements.txt           # List of dependencies
â”œâ”€â”€ README.md                  # Project documentation

'''
