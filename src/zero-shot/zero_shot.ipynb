{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dce363-96ec-4396-a02a-7a9583db789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries and Functions\n",
    "from zero_shot import (\n",
    "    run_zero_shot_experiment,\n",
    "    create_dataset\n",
    ")\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313bddd6-a63f-463d-8792-9c46277530d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3238578-88ac-4558-a42c-f057ad89b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../dataset/Research_Papers.csv\"\n",
    "n_samples_per_category = 2000  # Number of samples per ECDF_FCR_Category\n",
    "test_size = 0.10  # Test set size as a percentage of the total dataset\n",
    "\n",
    "# Define Feature Sets for Experiments\n",
    "feature_sets = [\n",
    "    [\"Title\", \"Abstract\"],  # Text Only\n",
    "    [\"Title\", \"Abstract\", \"Flesch Reading Ease\"],  # Text + Readability\n",
    "    [\"Title\", \"Abstract\", \"Flesch Reading Ease\", \"Gunning Fog Index\"]  # Text + All Readability\n",
    "]\n",
    "\n",
    "# Create Dataset (Knowledge Base and Test Set)\n",
    "df_knowledge_base, df_test = create_dataset(dataset_path, n_samples_per_category, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c284e0-5c4b-4cdd-9788-38761a9c1e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e58711d2-4604-42db-beb6-db0d33ff0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"llama3\", \"mistral\", \"gemma\"]\n",
    "\n",
    "predictions_files = [\n",
    "    \"../../results/llama3/llama3 zero-shot predictions.csv\",\n",
    "    \"../../results/mistral/mistral zero-shot predictions.csv\",\n",
    "    \"../../results/gemma/gemma zero-shot predictions.csv\"\n",
    "]\n",
    "metrics_files = [\n",
    "    \"../../results/metrics/llama3 zero-shot metrics.csv\",\n",
    "    \"../../results/metrics/mistral zero-shot metrics.csv\",\n",
    "    \"../../results/metrics/gemma zero-shot metrics.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f2576-286b-4b3d-919e-982163d1178d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc5f3fe-eb7f-4426-a296-e5e2c49310ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Zero-Shot Experiments for Each Model\n",
    "for model_name, predictions_file, metrics_file in zip(models, predictions_files, metrics_files):\n",
    "    print(f\"\\nðŸš€ Running Zero-Shot Experiment with {model_name} Model\")\n",
    "    run_zero_shot_experiment(\n",
    "        df_test, \n",
    "        feature_sets, \n",
    "        predictions_file, \n",
    "        metrics_file, \n",
    "        model_name=model_name\n",
    "    )\n",
    "\n",
    "    # Load and Display Results\n",
    "    df_eval = pd.read_csv(metrics_file)\n",
    "    print(f\"\\nðŸ“Š {model_name.capitalize()} Evaluation Results\")\n",
    "    print(df_eval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204f730-ed6e-4caf-b1fb-baa662b9881d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b04c1-71ea-46be-a39e-5951dd70d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and combine all metrics CSV files into a single DataFrame\n",
    "combined_df = pd.concat([pd.read_csv(file) for file in metrics_files], ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv(\"../../results/metrics/zero-shot metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64331550-9b97-4d45-9a3b-ea89d2c2a67f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc8b8bf-0342-43d8-856c-13d1b7c6ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete each file in the list\n",
    "for file in metrics_files:\n",
    "    try:\n",
    "        os.remove(file)\n",
    "        print(f\"Deleted: {file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a79e2f-3c22-418b-8fc4-3d1a9536ee51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
